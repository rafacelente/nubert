{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6776b36-53eb-4b66-b0c8-982a20251db1",
   "metadata": {},
   "source": [
    "## 08. Evaluating the Amount classification fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd9c4aa-4d5c-40e0-84fc-b6c882c6ec8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T22:49:25.922004Z",
     "iopub.status.busy": "2024-10-22T22:49:25.921127Z",
     "iopub.status.idle": "2024-10-22T22:49:30.112510Z",
     "shell.execute_reply": "2024-10-22T22:49:30.111709Z",
     "shell.execute_reply.started": "2024-10-22T22:49:25.921968Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import Tuple, List\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from nubert.datasets import AmountDataset\n",
    "from nubert.config import AmountConfig, TrainerConfig\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db168421-92d3-4354-b5e8-ebb19deecbca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T22:49:30.116920Z",
     "iopub.status.busy": "2024-10-22T22:49:30.116381Z",
     "iopub.status.idle": "2024-10-22T22:49:30.122686Z",
     "shell.execute_reply": "2024-10-22T22:49:30.121790Z",
     "shell.execute_reply.started": "2024-10-22T22:49:30.116898Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(\n",
    "        model_path: str,\n",
    "        tokenizer_path: str,\n",
    "    ) -> Tuple[AutoModelForSequenceClassification, AutoTokenizer]:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "def create_hf_dataset(data: pd.DataFrame) -> Dataset:\n",
    "    input_ids = [example[\"input_ids\"] for example in data]\n",
    "    labels = [example[\"label\"] for example in data]\n",
    "    return Dataset.from_dict({\"input_ids\": input_ids, \"labels\": labels})\n",
    "\n",
    "def prepare_data(\n",
    "        tokenizer: AutoTokenizer,\n",
    "        agency_name: str,\n",
    "        max_length: int = 512,\n",
    "        num_bins: int = 15,\n",
    "        num_transaction_sequences: int = 5,\n",
    "    ) -> Tuple[Dataset, pd.DataFrame]:\n",
    "    dataset = AmountDataset.from_raw_data(\n",
    "        root=\"./\",\n",
    "        fname=\"evaluation_raw\",\n",
    "        filter_list=[agency_name],\n",
    "        num_bins=num_bins,\n",
    "        model_name=tokenizer.name_or_path,\n",
    "        num_transaction_sequences=num_transaction_sequences,\n",
    "        max_seq_len=max_length,\n",
    "        stride=1,\n",
    "    )\n",
    "    table = dataset.trans_table\n",
    "    dataset = create_hf_dataset(dataset)\n",
    "    return dataset, table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e688009-b1b0-4b96-98fe-e6a1ae2f165b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T22:49:30.124397Z",
     "iopub.status.busy": "2024-10-22T22:49:30.124124Z",
     "iopub.status.idle": "2024-10-22T22:49:30.136459Z",
     "shell.execute_reply": "2024-10-22T22:49:30.135814Z",
     "shell.execute_reply.started": "2024-10-22T22:49:30.124372Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(\n",
    "        model: AutoModelForSequenceClassification,\n",
    "        dataset: Dataset,\n",
    "        table_size: int,\n",
    "        num_transaction_sequences: int,\n",
    "        stride: int = 1,\n",
    "        \n",
    "    ) -> Tuple[list, list]:\n",
    "    model.eval()\n",
    "    model.to(\"cuda\")\n",
    "    predictions = [0] * table_size\n",
    "    ground_truth = [0] * table_size\n",
    "\n",
    "    for i in range(num_transaction_sequences - 1):\n",
    "        predictions[i] = None\n",
    "        ground_truth[i] = None\n",
    "    if stride == 2:\n",
    "        predictions[num_transaction_sequences - 1] = None\n",
    "        ground_truth[num_transaction_sequences - 1] = None\n",
    "        predictions[num_transaction_sequences + 1] = None\n",
    "        ground_truth[num_transaction_sequences + 1] = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(dataset), desc=\"Predicting\"):\n",
    "            input_ids = torch.Tensor(batch['input_ids']).to(torch.int64).unsqueeze(0).to(\"cuda\")  # Add batch dimension\n",
    "            outputs = model(input_ids, attention_mask=torch.ones(input_ids.shape).to(torch.int64).to(\"cuda\"))\n",
    "            predicted_class = outputs.logits.softmax(dim=-1).argmax(dim=-1).item()\n",
    "            predictions[i] = predicted_class\n",
    "            ground_truth[i] = batch['labels']\n",
    "    \n",
    "    return predictions, ground_truth\n",
    "\n",
    "def compute_metrics(predictions: list, ground_truth: list) -> Tuple[float, float, list]:\n",
    "    accuracy = accuracy_score(ground_truth, predictions)\n",
    "    f1 = f1_score(ground_truth, predictions, average='weighted')\n",
    "    conf_matrix = confusion_matrix(ground_truth, predictions)\n",
    "    return accuracy, f1, conf_matrix\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, output_dir, num_transaction_sequences, num_bins, randomized):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(f\"{output_dir}/confusion_matrix-transactions-{num_transaction_sequences}-bins-{num_bins}-randomize-{str(randomized)}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_time_series(\n",
    "        df: pd.DataFrame,\n",
    "        output_dir: str,\n",
    "        num_transaction_sequences, num_bins, randomized\n",
    "    ):\n",
    "    agency_name = df['Agency Name'].iloc[0]\n",
    "    agency_data = [(row['Timestamp'], row['ground_truth'], row['predictions']) \n",
    "                   for i, row in df.iterrows()]\n",
    "    \n",
    "    timestamps, ground_truth, preds = zip(*sorted(agency_data))\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(timestamps, ground_truth, label='Ground Truth', marker='o')\n",
    "    plt.plot(timestamps, preds, label='Predicted', marker='x')\n",
    "    plt.title(f'Amount Prediction Over Time for Agency {agency_name}')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Amount Bin')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/time_series_agency_{agency_name}-{num_transaction_sequences}-bins-{num_bins}-randomize-{str(randomized)}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822b95e7-b31a-4c11-9bc8-e73f5d9353ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T22:49:30.137989Z",
     "iopub.status.busy": "2024-10-22T22:49:30.137755Z",
     "iopub.status.idle": "2024-10-22T23:04:07.730942Z",
     "shell.execute_reply": "2024-10-22T23:04:07.730173Z",
     "shell.execute_reply.started": "2024-10-22T22:49:30.137940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [06:25<00:00, 385.79s/it]\n",
      "Predicting: 112390it [07:43, 242.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-bins-15-randomize-False\n",
      "Accuracy: 0.3640\n",
      "F1 Score: 0.3339\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "num_bins_to_test = [15]\n",
    "num_transaction_sequences_to_test = [7]\n",
    "randomized_to_test = [False]\n",
    "\n",
    "for num_bins in num_bins_to_test:\n",
    "    for num_transaction_sequences in num_transaction_sequences_to_test:\n",
    "        for randomized in randomized_to_test:\n",
    "            model_name = f\"amount-transactions-{num_transaction_sequences}-stride-1-randomize-{randomized}-bins-{num_bins}\"\n",
    "            model_path = os.path.join(\"/notebooks/nubank/models/amount\", model_name)\n",
    "            tokenizer_path = model_path\n",
    "            output_dir = \"./images/\"\n",
    "            agency_name = \"OKLAHOMA STATE UNIVERSITY\"\n",
    "\n",
    "            model, tokenizer = load_model_and_tokenizer(model_path, tokenizer_path)\n",
    "            dataset, table = prepare_data(\n",
    "                tokenizer=tokenizer,\n",
    "                agency_name=agency_name,\n",
    "                num_bins=num_bins,\n",
    "                num_transaction_sequences=num_transaction_sequences,\n",
    "            )\n",
    "\n",
    "            predictions, ground_truth = predict(model, dataset, table_size=len(table), num_transaction_sequences=num_transaction_sequences)\n",
    "\n",
    "            table['predictions'] = predictions\n",
    "            table['ground_truth'] = ground_truth\n",
    "\n",
    "            table.to_csv(f\"{output_dir}/predictions-transactions-{num_transaction_sequences}-bins-{num_bins}-randomize-{str(randomized)}.csv\", index=False)\n",
    "\n",
    "            accuracy, f1, conf_matrix = compute_metrics(predictions, ground_truth)\n",
    "            \n",
    "            print(f\"{num_transaction_sequences}-bins-{num_bins}-randomize-{str(randomized)}\")\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "            plot_confusion_matrix(conf_matrix, output_dir, num_transaction_sequences, num_bins, randomized)\n",
    "            plot_time_series(table, output_dir, num_transaction_sequences, num_bins, randomized)\n",
    "\n",
    "            with open(f\"{output_dir}/metrics-transactions-{num_transaction_sequences}-bins-{num_bins}-randomize-{str(randomized)}.txt\", \"w\") as f:\n",
    "                f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "                f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
    "                \n",
    "            del model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
